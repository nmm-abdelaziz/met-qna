{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f09ffeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#start with importing the required libraries \n",
    "import pandas as pd\n",
    "import openai as oi\n",
    "import chromadb, chardet\n",
    "from chromadb.utils import embedding_functions\n",
    "import os, json \n",
    "import requests, time\n",
    "import math\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n",
    "from IPython.display import Image\n",
    "\n",
    "#creating global variables for further use \n",
    "OPENAI_API_KEY=\"OPENAI_KEY\"\n",
    "RESET_FILE_STATUS = -1\n",
    "deptID = 10\n",
    "deptName = \"Egyptian_Art\"\n",
    "query = \"egypt\"\n",
    "root_path = \"LOCAL_STORAGE_PATH\"+str(deptID)\n",
    "stride = 1000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f931317e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#method to format a clause to correct json parseable format \n",
    "def parseClause(value): \n",
    "    return str(value).replace(\"[\",\"\").replace(\"]\",\"\").replace(\"'\",\"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdf764a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#call OpenAI text embedding \n",
    "def text_embedding(text):\n",
    "    openai_client = oi.OpenAI(api_key = OPENAI_API_KEY)\n",
    "    response = openai_client.embeddings.create(model=\"text-embedding-ada-002\", input=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8566750d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parse the file statuses as a data structure (dictionary) from the reference \n",
    "def parse_file_status(): \n",
    "    file_status_file = open(root_path+\"/\"+deptName+\"_Ref.txt\",\"r\")\n",
    "    file_status_list = file_status_file.readlines()\n",
    "    status_dictionary = {}\n",
    "    for line in file_status_list: \n",
    "        fileName, fileStatus = line.split(\",\")\n",
    "        cr_counter = getCounter(fileName)\n",
    "        status_dictionary[cr_counter] = int(fileStatus)\n",
    "    file_status_file.close()\n",
    "    return status_dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffe0bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parse the countern (used as a partitioning index) from the fileName \n",
    "def getCounter(fileName): \n",
    "    return fileName.split(\".\")[0].replace(deptName,\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f958784b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the file status of the file wiht the specified counter/partition\n",
    "def get_file_entry(counter): \n",
    "    file_status_file = open(root_path+\"/\"+deptName+\"_Ref.txt\",\"r\")\n",
    "    file_status_list = file_status_file.readlines()\n",
    "    for file_status in file_status_list: \n",
    "        fileName = file_status.split(\",\")[0]\n",
    "        curr_counter = getCounter(fileName)\n",
    "        if(curr_counter == counter):\n",
    "            file_status_file.close()\n",
    "            if(int(file_status.split(\",\")[1])==1): \n",
    "                return True\n",
    "            else: \n",
    "                return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b0323c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_file_entry(counter) : \n",
    "    refFileName = root_path+\"/\"+deptName+\"_Ref.txt\"\n",
    "    parsed_status = parse_file_status()\n",
    "    if(counter!=RESET_FILE_STATUS):\n",
    "        parsed_status[counter] = 1                 \n",
    "    status_file = open(refFileName,\"w\")\n",
    "    prefix = deptName\n",
    "    suffix = \".0.csv\"\n",
    "    for key in parsed_status: \n",
    "        if(counter==RESET_FILE_STATUS):\n",
    "            status_file.write(prefix+str(key)+suffix+\", 0\"+os.linesep)\n",
    "        else:\n",
    "            status_file.write(prefix+str(key)+suffix+\", \"+str(parsed_status[key])+os.linesep)\n",
    "    status_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7596f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a reference file that stores the status of each object\n",
    "def createRefFile():\n",
    "    with open(root_path+\"/\"+deptName+\"_Ref.txt\", \"w\") as f:\n",
    "        list_of_files = sorted(os.listdir(root_path+\"/Files/\"))\n",
    "        prefix = deptName\n",
    "        suffix = \".0.csv\"\n",
    "        for file in list_of_files: \n",
    "            f.write(str(file)+\", 0\"+os.linesep)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7b052a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#init the client for chromadb\n",
    "client = chromadb.PersistentClient(path=\"<PATH_TO_CHROMADB>\")\n",
    "client.heartbeat()\n",
    "\n",
    "from chromadb.utils import embedding_functions\n",
    "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "                model_name=\"text-embedding-ada-002\", \n",
    "                api_key = OPENAI_API_KEY\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6a59fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create a file for storing the artwork items by monet from the MET API \n",
    "url = \"https://collectionapi.metmuseum.org/public/collection/v1/search?departmentId=\"+str(deptID)+\"&q=\"+query\n",
    "payload = {}\n",
    "headers = {'Connection': 'keep-alive',\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36', \n",
    "        'Upgrade-Insecure-Requests': '1',\n",
    "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
    "        'Accept-Language': 'en-US,en;q=0.9',\n",
    "        'Accept-Encoding': 'gzip, deflate'}\n",
    "\n",
    "#start the GET request to fetch the list of objectIDs \n",
    "response1 = requests.request(\"GET\", url, data=payload, headers = headers)\n",
    "\n",
    "object_id_strings = response1.text.split(\",\")\n",
    "objectIDs = json.loads(response1.text)['objectIDs']\n",
    "objectIDs.sort()\n",
    "\n",
    "print(\"Total number of Objects is \"+str(len(objectIDs)))\n",
    "\n",
    "Path(root_path).mkdir(parents=True, exist_ok=True)\n",
    "Path(root_path+\"/Images/\").mkdir(parents=True, exist_ok=True)\n",
    "Path(root_path+\"/Files/\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#iterate over all objects fetched \n",
    "root_file_path = root_path+\"/Files/\"+deptName\n",
    "file = open(root_file_path+\"0.0.csv\",\"w\")\n",
    "x=0\n",
    "#x = \n",
    "print(\"Starting the for loop\")\n",
    "for objectID in objectIDs: \n",
    "    if(objectID>=544725): \n",
    "        break\n",
    "#     if(objectID<548911):\n",
    "#         x = x+1\n",
    "#         continue;\n",
    "    if(x%stride==0 and x!=0): \n",
    "        print(x)\n",
    "        file.close()\n",
    "        file_path = root_file_path+str(x/stride)+\".csv\"\n",
    "        if os.path. exists(file_path):\n",
    "            os.remove(file_path)\n",
    "        file = open(file_path,\"w\")\n",
    "    #sleep for 1 second so as not to overwhelm the server with requests \n",
    "    #time.sleep(1)\n",
    "    x= x+1\n",
    "    #start teh get request to fetch this object details \n",
    "    url = 'https://collectionapi.metmuseum.org/public/collection/v1/objects/'+str(objectID)\n",
    "    payload = {}\n",
    "    response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "    #write the response to the file, with a delimeter of comma and new line \n",
    "    file.write(response.text+\",/n\")\n",
    "\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6e7404",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the reference file \n",
    "createRefFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec06a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optionally delete the collection and reset the file statuses in the reference file in case of a pause \n",
    "#client.delete_collection(name = deptName)\n",
    "#update_file_entry(RESET_FILE_STATUS)\n",
    "\n",
    "#create the collection, or get it in case of a pause \n",
    "collection = client.get_or_create_collection(name=deptName, embedding_function=openai_ef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ec0bc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create the headers for a browser get request call \n",
    "headers = {\n",
    "        'Connection': 'keep-alive',\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36', \n",
    "        'Upgrade-Insecure-Requests': '1',\n",
    "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
    "        'Accept-Language': 'en-US,en;q=0.9',\n",
    "        'Accept-Encoding': 'gzip, deflate'\n",
    "}\n",
    "\n",
    "#collection = client.get_or_create_collection(name=\"egypt_artwork_met_w_images\", embedding_function=openai_ef)\n",
    "collection = client.get_collection(name=deptName, embedding_function=openai_ef)\n",
    "\n",
    "\n",
    "fileList = os.listdir(root_path+\"/Files/\")\n",
    "#a counter created for the paritioning index used for the images \n",
    "\n",
    "for fileName in fileList:\n",
    "    try:\n",
    "        current_file = open(root_path+\"/Files/\"+fileName,\"r\")\n",
    "        try:\n",
    "            counter = getCounter(fileName)\n",
    "        except Exception as e: \n",
    "            print(\"Error with file name\")\n",
    "            print(fileName)\n",
    "        \n",
    "        print(\"Counter: \"+str(counter))\n",
    "        file_status = get_file_entry(counter)\n",
    "        if(file_status==True):\n",
    "            current_file.close()\n",
    "            print(\"file has been loaded \"+str(counter))\n",
    "            continue\n",
    "        \n",
    "        #read the json file and create a list of json tags by splitting at new line \n",
    "        artworks = current_file.readline().split(\",/n\")\n",
    "        current_file.close()\n",
    "        \n",
    "        #parse to json \n",
    "        json_ = json.loads(artworks[0])\n",
    "        \n",
    "        #parse the header to create the dataframe of artwork collection \n",
    "        artwork_keys = (\"part_index,\"+str(json_.keys()).replace(\"dict_keys([\",\"\").replace(\"])\",\"\").replace(\"'\",\"\").replace(\" \",\"\")).split(\",\")\n",
    "        \n",
    "        #create the dataframe with the index as the objectID \n",
    "        d_artwork = pd.DataFrame(columns = artwork_keys, index=[0])\n",
    "        d_artwork.set_index('objectID')\n",
    "        d_artwork.set_index('part_index')\n",
    "        \n",
    "        #create a dataframe for the objects and images \n",
    "        d_artwork_documents = pd.DataFrame(columns = ['part_index','objectID','objectDesc', 'image'])\n",
    "        d_artwork_documents.set_index('objectID')\n",
    "        d_artwork_documents.set_index('part_index')\n",
    "    \n",
    "        #creating a list of dictionnaries for the metadatas to be added to the collection \n",
    "        list_of_dictionaries = []\n",
    "        \n",
    "        for artwork in artworks: \n",
    "            \n",
    "            #pass the invalid inputs \n",
    "            if (str(artwork) == \"{\\\"message\\\":\\\"Not a valid object\\\"}\" or len(artwork)==0): \n",
    "                continue\n",
    "            \n",
    "            #load each artwork into a parsed json object, create a one liner of current artwork and concat with the \n",
    "            #list of artwork collection df \n",
    "            try: \n",
    "                json_ = json.loads(artwork)\n",
    "            except Exception as e: \n",
    "                if(\"codec can't decode byte\" in str(e)): \n",
    "                    encoding = chardet.detect(json_.encode())['encoding']\n",
    "                    a.encode(encoding).strip()\n",
    "          \n",
    "            #create a new row for the artwork dataframe\n",
    "            d_newrow_artwork = pd.DataFrame(columns= artwork_keys, index=[0])\n",
    "            d_newrow_artwork.loc[0] = json_\n",
    "            \n",
    "            #concatinate the new artwork record to the artowrks dataframe \n",
    "            d_artwork = pd.concat([d_artwork,d_newrow_artwork], ignore_index=True)\n",
    "\n",
    "            #include the new metadata record\n",
    "            list_of_dictionaries.append({'part_index': counter, 'id':d_newrow_artwork.loc[0]['objectID']})\n",
    "            \n",
    "            #formulate the docuemnt to be used by the vector db \n",
    "            currentDesc = \"The title of this artwork is \"+str(d_newrow_artwork.loc[0]['title'])+\".\"\n",
    "            if(str(d_newrow_artwork.loc[0]['artistDisplayName'])!=\"\"): \n",
    "                \"It is the work of \"+ str(d_newrow_artwork.loc[0]['artistDisplayName']) +\".  \"\n",
    "            if(str(d_newrow_artwork.loc[0]['accessionYear'])!=\"\"):\n",
    "                \"It resides at the MET in NYC, it was included to the collection on \"+str(d_newrow_artwork.loc[0]['accessionYear'])+\". \"\n",
    "            if(str(d_newrow_artwork.loc[0]['department'])!=\"\"):\n",
    "                \"It is part of the department of \"+str(d_newrow_artwork.loc[0]['department'])+ \". \"\n",
    "            if(str(d_newrow_artwork.loc[0]['period'])!=\"\"): \n",
    "                \"It is part of the period of \"+str(d_newrow_artwork.loc[0]['period'])+ \". \"\n",
    "            if(str(d_newrow_artwork.loc[0]['dynasty'])!=\"\"): \n",
    "                \"It is part of the dynasty of \"+str(d_newrow_artwork.loc[0]['dynasty'])+ \". \"\n",
    "            if(str(d_newrow_artwork.loc[0]['reign'])!=\"\"): \n",
    "                \"It is part of the reign of \"+str(d_newrow_artwork.loc[0]['reign'])+ \". \"\n",
    "            if(str(d_newrow_artwork.loc[0]['objectDate'])!=\"\"): \n",
    "                \"It was created on \"+str(d_newrow_artwork.loc[0]['objectDate'])+ \". \"\n",
    "            \n",
    "            #add the current row to the dataframe for artworks \n",
    "            d_newrow_artwork_documents = pd.DataFrame(columns= ['objectID','objectDesc', 'image'], index=[0])\n",
    "            d_newrow_artwork_documents.set_index('objectID')    \n",
    "            d_newrow_artwork_documents.loc[0] = [str(d_newrow_artwork.loc[0]['objectID']), currentDesc, d_newrow_artwork.loc[0]['objectURL']]\n",
    "            d_artwork_documents = pd.concat([d_artwork_documents,d_newrow_artwork_documents], ignore_index=True)\n",
    "            \n",
    "            \n",
    "            try: \n",
    "                #Download the image when applicable in a folder that has the name of the part_index\n",
    "                currentURL = d_newrow_artwork.loc[0]['primaryImage']\n",
    "                currentObjectID = d_newrow_artwork.loc[0]['objectID']\n",
    "            \n",
    "                #in case of image, create path and file, unless it has been stored already  \n",
    "                if(len(currentURL)!=0):\n",
    "                    pathName = root_path+\"/Images/P\"+str(counter)\n",
    "                    path = Path(pathName)\n",
    "                    if not path.exists():\n",
    "                        path.mkdir(parents=True)\n",
    "                    filePath = pathName+\"/\"+str(currentObjectID)+'.jpg'\n",
    "                    if(Path(filePath).exists() == False): \n",
    "                        with open(filePath, 'wb') as handle:\n",
    "                            response1 = requests.get(currentURL, stream=True, headers = headers)\n",
    "                            if not response1.ok:\n",
    "                                print(str(response1))\n",
    "                            for block in response1.iter_content(1024):\n",
    "                                if not block:\n",
    "                                    break\n",
    "                                handle.write(block)\n",
    "            except Exception as e: \n",
    "                print(e)\n",
    "            \n",
    "    \n",
    "#             #Optionally include this block for fetching tags and constituents, commented as it is not used for this dept. \n",
    "\n",
    "#             #check for the tags associated with this artwork, pass if there is none \n",
    "#             tags = d_newrow_artwork['tags']\n",
    "#             if tags[0] is not None:\n",
    "#                 currentDesc = currentDesc + \" It is decribed by the tags:\"\n",
    "#                 for tag in tags[0]:\n",
    "#                     if tag is not None:\n",
    "#                         #parse the contents of the tags into a json object \n",
    "#                         updatedTags = parseClause(tag).replace(\"None\",\"\\\" \\\"\")\n",
    "#                         json_ = json.loads(updatedTags)    \n",
    "#                         currentDesc = currentDesc + str(json_['term']) + \" which has this reference \" + str(json_['AAT_URL'])\n",
    "#             #check for the constituents associated with this artwork, pass if there is none \n",
    "#             constituents = d_newrow_artwork['constituents']\n",
    "#             if constituents[0] is not None: \n",
    "#                 currentDesc = currentDesc + \". It is associated with these constituents: \"\n",
    "#                 for constituent in constituents[0]:\n",
    "#                     if constituent is not None:            \n",
    "#                         #parse the contents of the constituents into a json object \n",
    "#                         updatedConst = parseClause(constituent).replace(\"None\",\"\\\" \\\"\")\n",
    "#                         json_ = json.loads(updatedConst)            \n",
    "#                         #associate the artwork with the constituent in the many to many list of tuples \n",
    "#                         currentDesc = currentDesc + str(json_['name']) + \" with the role of \" + str(json_['role']) + \" which has this reference \" + str(json_['constituentULAN_URL'])\n",
    "    \n",
    "            \n",
    "        #drop the row of nulls \n",
    "        d_artwork.drop(index=d_artwork.index[0], axis=0, inplace=True)\n",
    "        \n",
    "#       time.sleep(1)\n",
    "        #add the current stride of artworks to the vector db\n",
    "        try:\n",
    "            collection.add(\n",
    "                documents = d_artwork_documents['objectDesc'].tolist(),\n",
    "                metadatas = list_of_dictionaries,\n",
    "                ids = d_artwork_documents['objectID'].tolist())\n",
    "            \n",
    "        except Exception as e: \n",
    "                #rerun the add to vectordb in case of throttle in OpenAI during the add operation \n",
    "                if(\"Please try again in 7m12s\" in str(e)): \n",
    "                    print(\"Waiting 7m12s to start\")\n",
    "                    time.sleep(432)\n",
    "                    documents = d_artwork_documents['objectDesc'].tolist(),\n",
    "                    metadatas = list_of_dictionaries,\n",
    "                    ids = d_artwork_documents['objectID'].tolist()\n",
    "                elif(\"Please try again in 20s\" in str(e)):  \n",
    "                    print(\"Waiting 20s to start\")\n",
    "                    time.sleep(20)\n",
    "                    documents = d_artwork_documents['objectDesc'].tolist(),\n",
    "                    metadatas = list_of_dictionaries,\n",
    "                    ids = d_artwork_documents['objectID'].tolist()\n",
    "                else: \n",
    "                    print(e)\n",
    "                    \n",
    "        #update the reference file that the file has been added to the collection and update image paritioning index\n",
    "        update_file_entry(counter)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f98b769",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
